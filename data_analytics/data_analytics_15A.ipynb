{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & File Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import mysql.connector\n",
    "import transform\n",
    "\n",
    "\n",
    "# set max number of columns & rows to display\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run this cell to load data from a csv file\n",
    "df = pd.read_csv('./data/route_15A.csv', sep=\";\", na_values=['\\\\N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform a check to see how many rows and columns are in the file\n",
    "rows = df.shape[0]\n",
    "cols = df.shape[1]\n",
    "print()\n",
    "print(\"Before any data cleaning, the CSV file contains\", rows, \"rows and\", cols, \"columns.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Checks on the Data\n",
    "\n",
    "- Duplicate rows and columns\n",
    "- Null/empty features\n",
    "- Assign features as categorical or continuous\n",
    "- Constant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Duplicate Rows & Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "print()\n",
    "print('Duplicate rows:', df.duplicated()[df.duplicated() == True].shape[0])\n",
    "# Check for duplicate columns\n",
    "print('Duplicate columns:',df.columns.size - df.columns.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows or columns so nothing needs to be dropped here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Null/Empty Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform a check for null/empty columns\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with count of zero can be dropped as they contain no information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop null columns\n",
    "df = df.drop(columns=['tenderlot', 'suppressed_trip', 'justificationid_trip', 'passengers', 'passengersin', 'passengersout', 'distance_leavetimes', 'note_leavetimes', 'note_vehicle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Features as Continuous or Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check the data types of all rows after the file import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print data types of all rows\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign categorical and continous features, and update the type of all categorical features to 'category'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select columns containing categorical data\n",
    "categorical_columns = df[['datasource', 'dayofservice', 'tripid', 'lineid', 'routeid', 'direction', 'basin', \\\n",
    "                         'lastupdate_trip', 'note_trip', 'progrnumber', 'stoppointid', \\\n",
    "                          'suppressed_leavetimes', 'lastupdate_leavetimes']].columns\n",
    "\n",
    "# Convert data type to 'Category' for these columns\n",
    "for column in categorical_columns:\n",
    "    df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select columns containing continuous data \n",
    "# This is done by selecting columns with a numeric type - float64 or int64\n",
    "continuous_columns = df.select_dtypes(['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Constant Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print details for the categorical columns\n",
    "df[categorical_columns].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop constant features\n",
    "df = df.drop(columns=['datasource', 'basin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Constant Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the continuous columns\n",
    "df[continuous_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no constant continuous features so nothing needs to be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Analysis of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features that don't provide much information\n",
    "- Features that we won't be able to provide information on to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features we won't use\n",
    "df = df.drop(columns=['lastupdate_trip', 'note_trip', 'suppressed_leavetimes', 'justificationid_leavetimes', \\\n",
    "                      'lastupdate_leavetimes','vehicleid', 'distance_vehicle', 'minutes_vehicle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Checks for Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns containing categorical data\n",
    "categorical_columns = df[['dayofservice', 'tripid', 'lineid', 'routeid', 'direction', 'progrnumber', 'stoppointid']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the categorical columns\n",
    "df[categorical_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a full count for all categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns containing continuous data \n",
    "# This is done by selecting columns with a numeric type - float64 or int64\n",
    "continuous_columns = df.select_dtypes(['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the continuous columns\n",
    "df[continuous_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some rows missing data for **actualtime_arr_trip** and **actualtime_dep_trip**. This will be reviewed if these features are used in the future, currently they are not carried across when data is transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = transform.transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First re-assign the transformed data as continuous or categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns containing categorical data\n",
    "categorical_columns = df_transformed[['dayofservice', 'tripid', 'lineid', 'routeid', 'direction',  \\\n",
    "                         'progrnumber_first', 'stoppointid_first', \\\n",
    "                          'progrnumber_next', 'stoppointid_next']].columns\n",
    "\n",
    "# Convert data type to 'Category' for these columns\n",
    "for column in categorical_columns:\n",
    "    df_transformed[column] = df_transformed[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns containing continuous data \n",
    "# This is done by selecting columns with a numeric type - float64 or int64\n",
    "continuous_columns = df_transformed.select_dtypes(['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the categorical columns\n",
    "df_transformed[categorical_columns].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the continuous columns\n",
    "df_transformed[continuous_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Rows with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_transformed[pd.notnull(df_transformed['stoppointid_first'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_transformed[pd.notnull(df_transformed['stoppointid_next'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the categorical columns\n",
    "df_transformed[categorical_columns].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print details for the continuous columns\n",
    "df_transformed[continuous_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Plan - Before Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Data Quality Issue | Handling Strategy |\n",
    "|-------------------------|----------------------|------------------------------|\n",
    "| tenderlot       | All rows are null | Drop feature |\n",
    "| suppressed_trip | All rows are null | Drop feature |\n",
    "| justificationid_trip | All rows are null | Drop feature |\n",
    "| passengers | All rows are null | Drop feature | \n",
    "| passengersin | All rows are null | Drop feature |\n",
    "| passengersout | All rows are null | Drop feature |\n",
    "| distance_leavetimes | All rows are null | Drop feature |\n",
    "| note_leavetimes | All rows are null | Drop feature |\n",
    "| note_vehicle | All rows are null | Drop feature |\n",
    "| datasource | Constant feature | Drop feature |\n",
    "| lineid | Constant feature | This is constant because we just have data for one route loaded. At some point we may process more than one route together so will keep feature for now. May not be needed to train the model. |\n",
    "| basin | Constant feature | Drop feature |\n",
    "| lastupdate_trip | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| note_trip | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| suppressed_leavetimes | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| justifcationid_leavetimes | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| lastupdate_leavetimes | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| vehicleid | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| distance_vehicle | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| minutes_vehicle | Cannot be used to train model as we won't be able to provide this information | Drop feature |\n",
    "| actualtime_arr_trip | Missing values < 1% | Ignore for now as this feature is not brought across when data is transformed. |\n",
    "| actualtime_dep_trip | Missing values < 3% | Ignore for now as this feature is not brought across when data is transformed. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Plan - After Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Data Quality Issue | Handling Strategy |\n",
    "|-------------------------|----------------------|------------------------------|\n",
    "| stoppointid_first | Missing values ~ 1% | Drop affected rows |\n",
    "| actualtime_arr_stop_first | Missing values ~ 1%| Drop affected rows |\n",
    "| stoppointid_next | Missing values ~ 1% | Drop affected rows |\n",
    "| actualtime_arr_stop_next | Missing values ~ 1%| Drop affected rows |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for Transforming the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df.loc[5:100]\n",
    "df_test1 = df_test1.reset_index(drop=True)\n",
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed1 = transform.transform_data(df_test1)\n",
    "df_transformed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [df[:35], df[42:100]]\n",
    "df_test2 = pd.concat(pieces)\n",
    "df_test2 = df_test2.reset_index(drop=True)\n",
    "df_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed2 = transform.transform_data(df_test2)\n",
    "df_transformed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [df[:5], df[10:100]]\n",
    "df_test3 = pd.concat(pieces)\n",
    "df_test3 = df_test3.reset_index(drop=True)\n",
    "df_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed3 = transform.transform_data(df_test3)\n",
    "df_transformed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pieces = [df[:5], df[8:10], df[14:50]]\n",
    "df_test4 = pd.concat(pieces)\n",
    "df_test4 = df_test4.reset_index(drop=True)\n",
    "df_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed4 = transform.transform_data(df_test4)\n",
    "df_transformed4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
