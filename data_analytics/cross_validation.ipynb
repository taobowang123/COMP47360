{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to perform cross validation for the monthly machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time so that various tasks can be timed\n",
    "import time\n",
    "\n",
    "# import math for mathematical calculates\n",
    "import math\n",
    "\n",
    "# import pandas and numpy for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import from sklearn for model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# import pickle so that models can be saved to file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. August Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/august_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. September Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/september_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. October Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/october_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. November Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/november_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. December Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/december_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. January Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/january_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. February Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/february_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. March Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/march_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. April Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/april_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'school_hol', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. May Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/may_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. June Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/june_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. July Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 Import the Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/data_analytics/data/july_bus_data_cleaned.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Encode the Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features we will use to train the model are:\n",
    "\n",
    "- hour\n",
    "- weekday\n",
    "- peak\n",
    "\n",
    "weekday & peak are already binary features. We will encode hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode values for hour\n",
    "df_dummies = pd.get_dummies(df['hour'], prefix='hour')\n",
    "df = pd.concat([df, df_dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 Prepare the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the descriptive & target features for the training data\n",
    "X = df[['actualtime_arr_stop_first','segment_mean','weekday', 'segment_std','peak', 'rain', 'temp', 'hour_0','hour_1','hour_4','hour_5','hour_6','hour_7','hour_8','hour_9','hour_10','hour_11','hour_12','hour_13','hour_14','hour_15','hour_16','hour_17','hour_18','hour_19','hour_20','hour_21','hour_22','hour_23']]\n",
    "y = df.time_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/questions/44446501/how-to-standardize-data-with-sklearns-cross-val-score\n",
    "scaler = StandardScaler()\n",
    "gtb = GradientBoostingRegressor(max_depth=5, n_estimators=125)\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', gtb)])\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse = [math.sqrt(-1*x) for x in scores]\n",
    "print(\"\\nCross Validation RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
